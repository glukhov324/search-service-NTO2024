# НТО 2024: поиск достопримечательностей

Данные предоставлены для Екатеринбурга, Нижнего Новгорода, Владимира, Ярославля

Исходный датасет был соединён в один из датасетов для Екатеринбурга, Нижнего Новгорода, Владимира, Ярославля и частично очищен от чёрно-белых изображений и изображений-коллажей при помощи модели clip 

### Какие задачи решает сервис?

1. Определение по изображению топ-5 наиболее подходящих категорий и топ-5 наиболее подходящих названий достопримечательностей
2. Определение по текстовому описанию топ-5 наиболее подходящих изображений достопримечательностей

Для 1 пункта используется классификатор с двумя головами (одна голова определяет категорию места, другая голова определяет название места),
для извлечения признаков из изображения была выбрана архитектура MobileNet. Всего:  25 категорий и 387 названий мест

Целевая метрика соревнования: precision@5

Полученная модель имеет precision@5 = 0.76 для названий мест и precision@5 = 0.94 для категорий


Для пункта 2 используется модель ruberttiny2 для извлечения эмбеддингов из названий мест, применяется библиотека faiss 
для ранжирования названий из датасета относительно входящего текстового описания достопримечательности, для топ-5 наиболее подходящих названий из датасета
выдаются изображения, соответствующие этим названиям

python version - 3.10



## Скачайте всё содержимое [этой](https://drive.google.com/drive/folders/1NWGmIqbgzb2MQ9ad3PBifPaqbAaSR598?usp=sharing) директории гугл диска 

1. Положите файлы из скачанной папки predictor в src/predictor   
2. Положите файлы из скачанной папки cv_model в src/cv_model
3. Переместите скачанную папку data в корень проекта
4. Положите файлы из скачанной папки cv_model_train to cv_model_train

3 и 4 пункты необязательны для выполнения, если вы просто хотите протестировать сервис. 4 шаг необходим, если вы хотите
получить единый очищенный датасет из исходных данных. 5 шаг необходим, если вы хотите обучить cv-модель



## __Fast start with docker__:

Убедитесь, что вы выполнили пункты 1 и 2 из предыдущего шага

```sh
docker build -t nto:v1 .
docker run -p 8000:8000 --gpus=all nto:v1
```

документация сервиса будет доступна [здесь](http://0.0.0.0:8000/docs)

В demo_test_service.ipynb находится демонстрация работы сервиса


## __Installation guide__:

```sh
python3.10 -m venv venv
source venv/bin/activate
export PYTHONPATH=$PYTHONPATH:$PWD
python -m pip install --upgrade pip
pip install -r .\requirements.txt
pip install git+https://github.com/openai/CLIP.git
```


Если вы хотите заново получить очищенный датасет и эмбеддинги названий достопримечательностей 
(перед этим убедитесь, что вы выполнили пунккты 1-4 по скачиванию необходимых файлов из гугл диска):

* чтобы получить единый очищенный датасет из исходных данных: python dataset_prepare\dataset_prepare.py

* чтобы получить эмбеддинги названий достопримечательностей: python names_embs_prepare\embeddings_prepare.py



## __Start guide without docker__:

Перед запуском сервиса выполните все шаги по установке библиотек и скачиванию необходимых файлов

```sh
source venv/bin/activate
python -m uvicorn app:app --reload
```

документация сервиса будет доступна [здесь](http://0.0.0.0:8000/docs)